import uvicorn
from fastapi import FastAPI, HTTPException, UploadFile, File, Form
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import StreamingResponse
from pydantic import BaseModel
from typing import List, Optional
import pandas as pd
import io
import json
import os
import uuid
from typing import List, Optional, Dict
from datetime import datetime

from llm_service import DeepSeekLLM, LLMService
from data_model import default_store, Product
from agents import ProductSelectionAgent, MarketingCopyAgent

# åˆå§‹åŒ– FastAPI
app = FastAPI(title="AI Agent E-Commerce API", version="2.0")

# é…ç½® CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # å…è®¸æ‰€æœ‰æ¥æºè®¿é—®ï¼Œç”Ÿäº§ç¯å¢ƒè¯·æŒ‡å®šå…·ä½“åŸŸå
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# åˆå§‹åŒ–æœåŠ¡
llm = DeepSeekLLM()
selection_agent = ProductSelectionAgent(default_store, llm)
copy_agent = MarketingCopyAgent(llm)

# --- Pydantic Models ---

class ProductSimple(BaseModel):
    product_id: str
    title_en: str

class ProductDetail(BaseModel):
    product_id: str
    title_en: str
    category: str
    price_usd: float
    avg_rating: float
    monthly_sales: int
    main_market: str
    tags: str

class SelectionRequest(BaseModel):
    campaign_description: str
    target_market: Optional[str] = None
    top_k: int = 3

class SelectionResponse(BaseModel):
    products: List[ProductDetail]
    explanation: str

class CopyRequest(BaseModel):
    product_id: str
    target_language: str
    channel: str

class CopyResponse(BaseModel):
    copy_text: str

class ChatMessage(BaseModel):
    role: str  # 'user' or 'assistant'
    content: str

class ChatRequest(BaseModel):
    message: str
    context: Optional[str] = None
    history: Optional[List[ChatMessage]] = None
    session_id: Optional[str] = None

class ChatResponse(BaseModel):
    response: str
    message_id: str
    thinking: Optional[str] = None  # Agent çš„æ€è€ƒè¿‡ç¨‹


class FileAnalysisResponse(BaseModel):
    summary: str
    data_preview: dict
    column_info: dict

# --- å­˜å‚¨ä¸Šä¼ çš„æ•°æ®ï¼ˆä¸´æ—¶ï¼Œå®é™…åº”ç”¨ä¸­åº”ä½¿ç”¨æ•°æ®åº“æˆ–ç¼“å­˜ï¼‰
uploaded_data_store = {}

# --- èŠå¤©å†å²æŒä¹…åŒ– ---
HISTORY_FILE = "chat_history.json"
# ç»“æ„: { session_id: [messages] }
CHAT_SESSIONS: Dict[str, List[Dict]] = {}

def load_history():
    """ä»æ–‡ä»¶åŠ è½½èŠå¤©å†å²"""
    global CHAT_SESSIONS
    if os.path.exists(HISTORY_FILE):
        try:
            with open(HISTORY_FILE, "r", encoding="utf-8") as f:
                CHAT_SESSIONS = json.load(f)
        except Exception as e:
            print(f"Error loading history: {e}")
            CHAT_SESSIONS = {}

def save_history():
    """ä¿å­˜èŠå¤©å†å²åˆ°æ–‡ä»¶"""
    try:
        with open(HISTORY_FILE, "w", encoding="utf-8") as f:
            json.dump(CHAT_SESSIONS, f, ensure_ascii=False, indent=2)
    except Exception as e:
        print(f"Error saving history: {e}")

# åˆå§‹åŒ–æ—¶åŠ è½½å†å²
load_history()

# --- Endpoints ---

@app.get("/products", response_model=List[ProductSimple])
def list_products():
    """è·å–æ‰€æœ‰å¯ç”¨äº§å“åˆ—è¡¨ (ID + Title)"""
    products = default_store.list_products()
    return [
        ProductSimple(product_id=p.product_id, title_en=p.title_en)
        for p in products
    ]

@app.post("/selection/recommend", response_model=SelectionResponse)
def recommend_products(req: SelectionRequest):
    """æ ¹æ® Campaign æè¿°æ¨èäº§å“"""
    try:
        top_products, explanation = selection_agent.recommend_products(
            campaign_description=req.campaign_description,
            target_market=req.target_market,
            top_k=req.top_k
        )
        
        # Convert data_model.Product objects to Pydantic models
        product_details = []
        for p in top_products:
            product_details.append(ProductDetail(
                product_id=p.product_id,
                title_en=p.title_en,
                category=p.category,
                price_usd=p.price_usd,
                avg_rating=p.avg_rating,
                monthly_sales=p.monthly_sales,
                main_market=p.main_market,
                tags=p.tags
            ))
            
        return SelectionResponse(products=product_details, explanation=explanation)
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/marketing/generate", response_model=CopyResponse)
def generate_copy(req: CopyRequest):
    """ç”Ÿæˆè¥é”€æ–‡æ¡ˆ"""
    product = default_store.get_product(req.product_id)
    if not product:
        raise HTTPException(status_code=404, detail="Product not found")
    
    try:
        result = copy_agent.generate_copy(
            product=product,
            target_language=req.target_language,
            channel=req.channel
        )
        return CopyResponse(copy_text=result)
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/agent/history", response_model=List[ChatMessage])
def get_chat_history(session_id: Optional[str] = None):
    """è·å–å†å²å¯¹è¯è®°å½•"""
    if session_id and session_id in CHAT_SESSIONS:
        return [
            ChatMessage(role=msg["role"], content=msg["content"])
            for msg in CHAT_SESSIONS[session_id]
        ]
    return []

@app.post("/agent/chat", response_model=ChatResponse)
def chat_with_agent(req: ChatRequest):
    """é€šç”¨æ™ºèƒ½ä½“å¯¹è¯æ¥å£ï¼ˆæ”¯æŒå¤šè½®å¯¹è¯ï¼‰"""
    try:
        # 1. ç¡®å®šä¼šè¯ä¸Šä¸‹æ–‡
        session_id = req.session_id
        current_history = []

        if session_id:
            is_temp_session = session_id.startswith('temp_')
            if not is_temp_session and session_id not in CHAT_SESSIONS:
                CHAT_SESSIONS[session_id] = []
                current_history = CHAT_SESSIONS[session_id]
            elif not is_temp_session:
                current_history = CHAT_SESSIONS[session_id]

        # 2. ä¿å­˜ç”¨æˆ·æ¶ˆæ¯åˆ°å†å²
        if session_id and not session_id.startswith('temp_'):
            user_msg_entry = {
                "role": "user",
                "content": req.message,
                "timestamp": datetime.now().isoformat()
            }
            if current_history is not None:
                current_history.append(user_msg_entry)
                save_history()

        # æ£€æµ‹åˆ†ææ¨¡å¼
        mode_prompts = {
            '[å¸‚åœºè¶‹åŠ¿åˆ†ææ¨¡å¼]': "You are a market analysis expert. Focus on market trends, opportunities, competitive landscape, and data-driven insights. Provide actionable recommendations based on data.",
            '[é€‰å“ç­–ç•¥å»ºè®®æ¨¡å¼]': "You are a product selection strategist. Focus on product recommendations, category analysis, profit potential, and market fit. Use data to support your suggestions.",
            '[å¹¿å‘Šä¼˜åŒ–å»ºè®®æ¨¡å¼]': "You are an advertising optimization expert. Focus on ad performance, ROI improvement, targeting strategies, and campaign optimization. Provide specific, measurable advice.",
            '[è½¬åŒ–ç‡ä¼˜åŒ–æ¨¡å¼]': "You are a conversion rate optimization specialist. Focus on user experience, funnel optimization, A/B testing, and conversion tactics. Give practical improvement steps."
        }

        system_prompt = "You are CogniMark, a helpful AI assistant specialized in cross-border e-commerce, product selection, and marketing. You provide professional, actionable advice. Maintain conversation context and refer to previous messages when relevant."
        user_message = req.message
        detected_mode = "æ™®é€šæ¨¡å¼"

        for mode_key, mode_system in mode_prompts.items():
            if user_message.startswith(mode_key):
                system_prompt = mode_system + " Maintain conversation context and refer to previous messages when relevant."
                user_message = user_message.replace(mode_key, '').strip()
                detected_mode = mode_key.replace('[', '').replace(']', '')
                break

        # æ”¶é›†ä¸Šä¼ æ•°æ®ä¸Šä¸‹æ–‡
        uploaded_data_context = ""
        if uploaded_data_store:
            uploaded_data_context = "\n\nã€å·²ä¸Šä¼ çš„å¤–éƒ¨æ•°æ®ã€‘\n"
            for filename, data_info in uploaded_data_store.items():
                uploaded_data_context += f"- {filename}: {data_info['rows']}è¡Œ Ã— {data_info['columns']}åˆ— | åˆ—å: {', '.join(data_info['column_names'])}\n"
                # æ·»åŠ æ•°æ®é¢„è§ˆï¼ˆå…³é”®ä¿®å¤ï¼šè®© AI èƒ½çœ‹åˆ°æ–‡ä»¶å†…å®¹ï¼‰
                if 'dataframe' in data_info:
                    try:
                        df = data_info['dataframe']
                        # é¢„è§ˆå‰ 10 è¡Œï¼Œä½¿ç”¨ CSV æ ¼å¼
                        preview = df.head(10).to_csv(index=False)
                        uploaded_data_context += f"\n[æ•°æ®é¢„è§ˆ - å‰10è¡Œ]:\n{preview}\n\n"
                    except Exception as e:
                        print(f"Error generating preview for {filename}: {e}")

        # æ”¶é›†å†å²å¯¹è¯ä¸Šä¸‹æ–‡
        history_context = ""
        if current_history and len(current_history) > 1:
            history_context = "\n\nã€å†å²å¯¹è¯æ‘˜è¦ã€‘\n"
            for msg in current_history[-3:-1]:  # åªå–æœ€è¿‘3æ¡
                role = "ç”¨æˆ·" if msg["role"] == "user" else "åŠ©æ‰‹"
                history_context += f"- {role}: {msg['content'][:100]}{'...' if len(msg['content']) > 100 else ''}\n"

        # æ„å»º LLM å†å²ä¸Šä¸‹æ–‡
        llm_history = []
        if session_id and not session_id.startswith('temp_'):
            if current_history:
                for msg in current_history[:-1]:
                    llm_history.append({
                        "role": msg["role"],
                        "content": msg["content"]
                    })
        elif req.history:
            for msg in req.history:
                llm_history.append({
                    "role": msg.role,
                    "content": msg.content
                })

        # ç”Ÿæˆæ·±åº¦æ€è€ƒè¿‡ç¨‹
        thinking_prompt = f"""ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ AI åŠ©æ‰‹ CogniMarkã€‚ç°åœ¨è¯·ä½ åˆ†æç”¨æˆ·çš„é—®é¢˜ï¼Œå¹¶å±•ç¤ºä½ çš„æ€è€ƒè¿‡ç¨‹ã€‚

ã€ç”¨æˆ·é—®é¢˜ã€‘
{req.message}

ã€å½“å‰æ¨¡å¼ã€‘
{detected_mode}

ã€å¯ç”¨ä¸Šä¸‹æ–‡ã€‘
{uploaded_data_context if uploaded_data_context else "æ— é¢å¤–æ•°æ®"}
{history_context if history_context else "æ— å†å²å¯¹è¯"}

ã€ä½ çš„ä»»åŠ¡ã€‘
è¯·æŒ‰ä»¥ä¸‹ç»“æ„å±•ç¤ºä½ çš„æ·±åº¦æ€è€ƒè¿‡ç¨‹ï¼š

## ç”¨æˆ·è¾“å…¥åˆ†æ
- åˆ†æç”¨æˆ·çš„é—®é¢˜ç±»å‹ã€æ ¸å¿ƒè¯‰æ±‚ã€æ½œåœ¨éœ€æ±‚
- è¯†åˆ«å…³é”®ä¿¡æ¯å’ŒèƒŒæ™¯

## é—®é¢˜ç†è§£
- ä»ä¸“ä¸šè§’åº¦è§£è¯»é—®é¢˜çš„æœ¬è´¨
- åˆ¤æ–­éœ€è¦å“ªäº›çŸ¥è¯†æˆ–å·¥å…·æ¥å›ç­”

## æ€è€ƒè·¯å¾„
- å±•ç¤ºä½ çš„æ¨ç†é€»è¾‘
- è¯´æ˜ä¸ºä»€ä¹ˆé€‰æ‹©è¿™ç§å›ç­”æ–¹å¼
- å¦‚æœæœ‰å¤šä¸ªå¯èƒ½çš„è§£å†³æ–¹æ¡ˆï¼Œè¯´æ˜ä½ é€‰æ‹©çš„ç†ç”±

## å›ç­”ç­–ç•¥
- è¯´æ˜ä½ å°†å¦‚ä½•ç»„ç»‡å›ç­”
- å¼ºè°ƒå›ç­”çš„é‡ç‚¹å’Œç»“æ„

è¯·ç”¨ä¸­æ–‡å›ç­”ï¼Œè¯­è¨€è¦è‡ªç„¶æµç•…ï¼Œå±•ç¤ºçœŸå®çš„æ€è€ƒè¿‡ç¨‹ã€‚"""

        # è°ƒç”¨ LLM ç”Ÿæˆæ€è€ƒè¿‡ç¨‹
        thinking_content = llm.chat(
            "ä½ æ˜¯ CogniMark çš„æ€è€ƒæ¨¡å—ã€‚è¯·å±•ç¤ºä½ çš„æ·±åº¦æ€è€ƒè¿‡ç¨‹ï¼Œå¸®åŠ©ç”¨æˆ·ç†è§£ä½ çš„åˆ†æé€»è¾‘ã€‚",
            thinking_prompt,
            history=[]  # æ€è€ƒè¿‡ç¨‹ä¸éœ€è¦å†å²
        )

        # æ„å»ºæœ€ç»ˆæç¤º
        final_prompt = ""
        if req.context:
            final_prompt += f"Context: {req.context}\n"
        if uploaded_data_context:
            final_prompt += uploaded_data_context + "\n"
        final_prompt += f"User question: {user_message}"

        # ç”Ÿæˆæœ€ç»ˆå›ç­”
        response_text = llm.chat(system_prompt, final_prompt, history=llm_history)

        # ä¿å­˜åŠ©æ‰‹å›å¤
        if session_id and not session_id.startswith('temp_'):
            assistant_msg_entry = {
                "role": "assistant",
                "content": response_text,
                "timestamp": datetime.now().isoformat()
            }
            if current_history is not None:
                current_history.append(assistant_msg_entry)
                save_history()

        return ChatResponse(
            response=response_text,
            message_id=str(uuid.uuid4()),
            thinking=thinking_content
        )
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/agent/chat/stream")
async def chat_with_agent_stream(req: ChatRequest):
    """
    æµå¼èŠå¤©æ¥å£ - å®æ—¶å±•ç¤ºæ€è€ƒè¿‡ç¨‹å’Œå›ç­”

    ä½¿ç”¨ Chain of Thought (CoT) è®©æ¨¡å‹å±•ç¤ºçœŸå®æ¨ç†è¿‡ç¨‹
    """
    async def generate_stream():
        try:
            import asyncio

            # 1. ç¡®å®šä¼šè¯ä¸Šä¸‹æ–‡
            session_id = req.session_id
            current_history = []

            if session_id:
                is_temp_session = session_id.startswith('temp_')
                if not is_temp_session and session_id not in CHAT_SESSIONS:
                    CHAT_SESSIONS[session_id] = []
                    current_history = CHAT_SESSIONS[session_id]
                elif not is_temp_session:
                    current_history = CHAT_SESSIONS[session_id]

            # 2. ä¿å­˜ç”¨æˆ·æ¶ˆæ¯
            if session_id and not session_id.startswith('temp_'):
                user_msg_entry = {
                    "role": "user",
                    "content": req.message,
                    "timestamp": datetime.now().isoformat()
                }
                if current_history is not None:
                    current_history.append(user_msg_entry)
                    save_history()

            # æ£€æµ‹åˆ†ææ¨¡å¼
            mode_prompts = {
                '[å¸‚åœºè¶‹åŠ¿åˆ†ææ¨¡å¼]': "You are a market analysis expert. Focus on market trends, opportunities, competitive landscape, and data-driven insights. Provide actionable recommendations based on data.",
                '[é€‰å“ç­–ç•¥å»ºè®®æ¨¡å¼]': "You are a product selection strategist. Focus on product recommendations, category analysis, profit potential, and market fit. Use data to support your suggestions.",
                '[å¹¿å‘Šä¼˜åŒ–å»ºè®®æ¨¡å¼]': "You are an advertising optimization expert. Focus on ad performance, ROI improvement, targeting strategies, and campaign optimization. Provide specific, measurable advice.",
                '[è½¬åŒ–ç‡ä¼˜åŒ–æ¨¡å¼]': "You are a conversion rate optimization specialist. Focus on user experience, funnel optimization, A/B testing, and conversion tactics. Give practical improvement steps."
            }

            system_prompt = "You are CogniMark, a helpful AI assistant specialized in cross-border e-commerce, product selection, and marketing. You provide professional, actionable advice. Maintain conversation context and refer to previous messages when relevant."
            user_message = req.message

            for mode_key, mode_system in mode_prompts.items():
                if user_message.startswith(mode_key):
                    system_prompt = mode_system + " Maintain conversation context and refer to previous messages when relevant."
                    user_message = user_message.replace(mode_key, '').strip()
                    break

            # æ”¶é›†ä¸Šä¸‹æ–‡
            uploaded_data_context = ""
            if uploaded_data_store:
                uploaded_data_context = "\n\nã€å·²ä¸Šä¼ çš„å¤–éƒ¨æ•°æ®ã€‘\n"
                for filename, data_info in uploaded_data_store.items():
                    uploaded_data_context += f"- {filename}: {data_info['rows']}è¡Œ Ã— {data_info['columns']}åˆ—\n"
                    # æ·»åŠ æ•°æ®é¢„è§ˆï¼ˆå…³é”®ä¿®å¤ï¼šè®© AI èƒ½çœ‹åˆ°æ–‡ä»¶å†…å®¹ï¼‰
                    if 'dataframe' in data_info:
                        try:
                            df = data_info['dataframe']
                            # é¢„è§ˆå‰ 10 è¡Œï¼Œä½¿ç”¨ CSV æ ¼å¼
                            preview = df.head(10).to_csv(index=False)
                            uploaded_data_context += f"\n[æ•°æ®é¢„è§ˆ - å‰10è¡Œ]:\n{preview}\n\n"
                        except Exception as e:
                            print(f"Error generating preview for {filename}: {e}")

            # ğŸ“š ä½¿ç”¨å•†å“æ£€ç´¢ç³»ç»ŸæŸ¥è¯¢æ•°æ®
            database_context = ""
            try:
                from rag.product_rag import get_product_rag

                # è·å–å•†å“æ£€ç´¢å®ä¾‹
                product_rag = get_product_rag()

                # æ‰§è¡Œæ£€ç´¢
                search_result = product_rag.search(
                    query=user_message,
                    top_k=20  # è¿”å›æœ€å¤š20æ¡ç»“æœ
                )

                # æ ¼å¼åŒ–ç»“æœ
                if search_result["total"] > 0:
                    database_context = product_rag.format_for_llm(search_result)

            except Exception as e:
                # å¦‚æœæŸ¥è¯¢å¤±è´¥ï¼Œä¸å½±å“æ­£å¸¸å¯¹è¯
                import traceback
                print(f"äº§å“RAGæŸ¥è¯¢é”™è¯¯: {e}")
                traceback.print_exc()

            # æ„å»º LLM å†å²ä¸Šä¸‹æ–‡
            llm_history = []
            if session_id and not session_id.startswith('temp_'):
                if current_history:
                    for msg in current_history[:-1]:
                        llm_history.append({
                            "role": msg["role"],
                            "content": msg["content"]
                        })
            elif req.history:
                for msg in req.history:
                    llm_history.append({
                        "role": msg.role,
                        "content": msg.content
                    })

            # ä½¿ç”¨ CoT prompting è®©æ¨¡å‹å±•ç¤ºçœŸå®æ€è€ƒè¿‡ç¨‹ï¼ˆä¸­æ–‡ï¼‰
            # ä½¿ç”¨ç‰¹æ®Šåˆ†éš”ç¬¦
            cot_system_prompt = system_prompt + "\n\né‡è¦æç¤ºï¼šåœ¨å›ç­”ä¹‹å‰ï¼Œä½ å¿…é¡»å±•ç¤ºä½ çš„æ€è€ƒè¿‡ç¨‹ã€‚è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹æ ¼å¼ï¼š\n\n[æ·±åº¦æ€è€ƒ]\né¦–å…ˆï¼Œåˆ†æç”¨æˆ·çš„é—®é¢˜...\nç„¶åï¼Œè€ƒè™‘ä¸Šä¸‹æ–‡ä¿¡æ¯...\næœ€åï¼Œç¡®å®šå›ç­”æ–¹æ¡ˆ...\n\n[å›ç­”]\nç°åœ¨æä¾›ä½ çš„æ¸…æ™°ã€ç®€æ´çš„å›ç­”ã€‚"

            # æ„å»ºæœ€ç»ˆæç¤ºï¼Œå¼ºåˆ¶è¦æ±‚æ˜¾ç¤ºæ€è€ƒè¿‡ç¨‹ï¼ˆä¸­æ–‡ï¼‰
            final_prompt = f"""è¯·é€æ­¥å±•ç¤ºä½ çš„æ€è€ƒè¿‡ç¨‹ï¼Œç„¶åç»™å‡ºæœ€ç»ˆå›ç­”ã€‚

"""
            if req.context:
                final_prompt += f"ä¸Šä¸‹æ–‡: {req.context}\n\n"
            if uploaded_data_context:
                final_prompt += f"å¯ç”¨æ•°æ®: {uploaded_data_context}\n\n"
            if database_context:
                final_prompt += f"{database_context}\n\n"
            final_prompt += f"ç”¨æˆ·é—®é¢˜: {user_message}\n\n"""

            final_prompt += """é‡è¦æ ¼å¼è¦æ±‚ï¼š
ä½ å¿…é¡»æŒ‰ç…§ä»¥ä¸‹ç»“æ„å›ç­”ï¼š

[æ·±åº¦æ€è€ƒ]
[åœ¨æ­¤å¤„é€æ­¥å±•ç¤ºä½ çš„æ¨ç†è¿‡ç¨‹ - åˆ†æé—®é¢˜ã€è€ƒè™‘å¯ç”¨ä¿¡æ¯ã€è§„åˆ’å›ç­”ç­–ç•¥]

[å›ç­”]
[åœ¨æ­¤å¤„ç»™å‡ºä½ çš„æ¸…æ™°å›ç­”]

æ€è€ƒè¿‡ç¨‹åº”è¯¥è¯¦ç»†ï¼Œå±•ç¤ºä½ çš„çœŸå®æ¨ç†é€»è¾‘ã€‚è¯·ç”¨ä¸­æ–‡è¿›è¡Œæ€è€ƒã€‚"""

            # æµå¼è°ƒç”¨ï¼Œä½¿ç”¨å»¶è¿Ÿå‘é€ç­–ç•¥æ£€æµ‹åˆ†éš”ç¬¦
            in_thinking = False
            thinking_buffer = ""
            response_buffer = ""

            # åˆ†éš”ç¬¦æ¨¡å¼ï¼ˆä¸­æ–‡ï¼‰
            thinking_start_pattern = "[æ·±åº¦æ€è€ƒ]"
            answer_start_pattern = "[å›ç­”]"

            # å»¶è¿Ÿç¼“å†²åŒº - ä¿å­˜å¯èƒ½åŒ…å«åˆ†éš”ç¬¦çš„å†…å®¹
            # ç¼“å†²åŒºå¤§å°è®¾ç½®ä¸º50ï¼Œç¡®ä¿èƒ½å®¹çº³åˆ†éš”ç¬¦ï¼ˆæœ€é•¿çº¦21å­—ç¬¦ï¼‰
            pending_buffer = ""
            BUFFER_SIZE = 50

            def send_content(content: str, is_thinking: bool):
                """å‘é€å†…å®¹çš„è¾…åŠ©å‡½æ•°"""
                if not content:
                    return
                escaped = content.replace('\n', '\\n').replace('"', '\\"')
                event_type = "thinking" if is_thinking else "response"
                return f"event: {event_type}\ndata: {{\"content\": \"{escaped}\"}}\n\n"

            for chunk in llm.stream_chat(cot_system_prompt, final_prompt, history=llm_history):
                if not chunk:
                    continue

                # å°†chunkæ·»åŠ åˆ°å¾…å¤„ç†ç¼“å†²åŒº
                pending_buffer += chunk

                # åœ¨éæ€è€ƒçŠ¶æ€ä¸‹æ£€æµ‹æ€è€ƒå¼€å§‹æ ‡è®°
                if not in_thinking and thinking_start_pattern in pending_buffer:
                    # å‘é€æ ‡è®°ä¹‹å‰çš„å†…å®¹ï¼ˆå¦‚æœæœ‰ï¼‰
                    parts = pending_buffer.split(thinking_start_pattern, 1)
                    if parts[0].strip():
                        yield send_content(parts[0], False)
                    # æ ‡è®°æ€è€ƒå¼€å§‹
                    yield f"event: thinking_start\ndata: {{}}\n\n"
                    in_thinking = True
                    # ä¿ç•™æ ‡è®°ä¹‹åçš„å†…å®¹
                    pending_buffer = parts[1] if len(parts) > 1 else ""
                    continue

                # åœ¨æ€è€ƒçŠ¶æ€ä¸‹æ£€æµ‹ç­”æ¡ˆå¼€å§‹æ ‡è®°
                if in_thinking and answer_start_pattern in pending_buffer:
                    # å‘é€ç­”æ¡ˆæ ‡è®°ä¹‹å‰çš„æ€è€ƒå†…å®¹
                    parts = pending_buffer.split(answer_start_pattern, 1)
                    if parts[0].strip():
                        yield send_content(parts[0], True)
                    # æ ‡è®°æ€è€ƒå®Œæˆ
                    yield f"event: thinking_done\ndata: {{}}\n\n"
                    in_thinking = False
                    # ä¿ç•™æ ‡è®°ä¹‹åçš„å†…å®¹
                    pending_buffer = parts[1] if len(parts) > 1 else ""
                    continue

                # å¦‚æœç¼“å†²åŒºå¤ªé•¿ï¼Œä¸”æ²¡æœ‰æ£€æµ‹åˆ°åˆ†éš”ç¬¦ï¼Œåˆ™å‘é€å†…å®¹
                # ä¿ç•™æœ€åBUFFER_SIZEä¸ªå­—ç¬¦ç”¨äºè·¨chunkæ£€æµ‹
                if len(pending_buffer) > BUFFER_SIZE:
                    send_now = pending_buffer[:-BUFFER_SIZE]
                    pending_buffer = pending_buffer[-BUFFER_SIZE:]

                    if send_now:
                        thinking_buffer += send_now
                        response_buffer += send_now
                        yield send_content(send_now, in_thinking)
                        await asyncio.sleep(0.01)

            # å‘é€å‰©ä½™çš„å¾…å¤„ç†å†…å®¹
            if pending_buffer.strip():
                pending_escaped = pending_buffer.replace('\n', '\\n').replace('"', '\\"')
                event_type = "thinking" if in_thinking else "response"
                yield f"event: {event_type}\ndata: {{\"content\": \"{pending_escaped}\"}}\n\n"

            # å¦‚æœä»åœ¨æ€è€ƒä¸­ï¼Œå‘é€æ€è€ƒå®Œæˆäº‹ä»¶
            if in_thinking:
                yield f"event: thinking_done\ndata: {{}}\n\n"

            # ä¿å­˜å®Œæ•´å¯¹è¯åˆ°å†å²
            if session_id and not session_id.startswith('temp_'):
                full_response = thinking_buffer + response_buffer
                assistant_msg_entry = {
                    "role": "assistant",
                    "content": full_response,
                    "timestamp": datetime.now().isoformat()
                }
                if current_history is not None:
                    current_history.append(assistant_msg_entry)
                    save_history()

            yield f"event: done\ndata: {{}}\n\n"

        except Exception as e:
            error_msg = str(e).replace('"', '\\"')
            yield f"event: error\ndata: {{\"message\": \"{error_msg}\"}}\n\n"

    return StreamingResponse(
        generate_stream(),
        media_type="text/event-stream",
        headers={
            "Cache-Control": "no-cache",
            "Connection": "keep-alive",
            "X-Accel-Buffering": "no",
        }
    )

@app.post("/upload/excel", response_model=FileAnalysisResponse)
async def upload_excel(file: UploadFile = File(...)):
    """ä¸Šä¼  Excel/CSV æ–‡ä»¶ï¼ˆä»…åŠ è½½ï¼Œä¸åˆ†æï¼‰"""
    try:
        # æ£€æŸ¥æ–‡ä»¶ç±»å‹
        is_csv = file.filename.endswith('.csv')
        is_excel = file.filename.endswith('.xlsx') or file.filename.endswith('.xls')
        
        if not (is_csv or is_excel):
            raise HTTPException(status_code=400, detail="åªæ”¯æŒ Excel (.xlsx, .xls) æˆ– CSV (.csv) æ–‡ä»¶")
        
        # è¯»å–æ–‡ä»¶
        contents = await file.read()
        
        if is_csv:
            # å°è¯•ä¸åŒçš„ç¼–ç 
            try:
                df = pd.read_csv(io.BytesIO(contents), encoding='utf-8')
            except UnicodeDecodeError:
                try:
                    df = pd.read_csv(io.BytesIO(contents), encoding='gbk')
                except UnicodeDecodeError:
                    df = pd.read_csv(io.BytesIO(contents), encoding='latin1')
        else:
            df = pd.read_excel(io.BytesIO(contents))
        
        # åŸºæœ¬ä¿¡æ¯
        rows, cols = df.shape
        column_names = df.columns.tolist()
        
        # æ•°æ®é¢„è§ˆï¼ˆå‰5è¡Œï¼‰
        preview = df.head(5).to_dict(orient='records')
        
        # åˆ—ä¿¡æ¯ï¼ˆæ•°æ®ç±»å‹ã€éç©ºæ•°é‡ç­‰ï¼‰
        column_info = {}
        for col in df.columns:
            column_info[col] = {
                'dtype': str(df[col].dtype),
                'non_null_count': int(df[col].count()),
                'null_count': int(df[col].isnull().sum()),
                'unique_count': int(df[col].nunique())
            }
            
            # å¦‚æœæ˜¯æ•°å€¼å‹ï¼Œæ·»åŠ ç»Ÿè®¡ä¿¡æ¯
            if pd.api.types.is_numeric_dtype(df[col]):
                column_info[col]['mean'] = float(df[col].mean()) if not df[col].isnull().all() else None
                column_info[col]['min'] = float(df[col].min()) if not df[col].isnull().all() else None
                column_info[col]['max'] = float(df[col].max()) if not df[col].isnull().all() else None
        
        # å­˜å‚¨æ•°æ®ä¿¡æ¯ï¼ˆç”¨äºåç»­åˆ†æï¼‰
        uploaded_data_store[file.filename] = {
            'dataframe': df,
            'rows': rows,
            'columns': cols,
            'column_names': column_names
        }
        
        # åªè¿”å›åŸºæœ¬ä¿¡æ¯ï¼Œä¸è¿›è¡Œ AI åˆ†æ
        summary = f"æ–‡ä»¶å·²æˆåŠŸåŠ è½½ï¼\n\næ•°æ®è§„æ¨¡: {rows} è¡Œ Ã— {cols} åˆ—\nåˆ—å: {', '.join(column_names[:5])}{'...' if len(column_names) > 5 else ''}"
        
        return FileAnalysisResponse(
            summary=summary,
            data_preview={'rows': preview[:5]},
            column_info=column_info
        )
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"æ–‡ä»¶å¤„ç†å¤±è´¥: {str(e)}")

@app.get("/upload/files")
def list_uploaded_files():
    """è·å–å·²ä¸Šä¼ æ–‡ä»¶åˆ—è¡¨"""
    return {
        "files": [
            {
                "filename": filename,
                "rows": info['rows'],
                "columns": info['columns'],
                "column_names": info['column_names']
            }
            for filename, info in uploaded_data_store.items()
        ]
    }

@app.delete("/upload/file/{filename}")
def delete_uploaded_file(filename: str):
    """åˆ é™¤å·²ä¸Šä¼ çš„æ–‡ä»¶"""
    if filename in uploaded_data_store:
        del uploaded_data_store[filename]
        return {"message": f"æ–‡ä»¶ {filename} å·²åˆ é™¤"}
    else:
        raise HTTPException(status_code=404, detail="æ–‡ä»¶ä¸å­˜åœ¨")



# ==================== æ•°æ®å¯¼å…¥æ¥å£ ====================

class ColumnMapping(BaseModel):
    """åˆ—åæ˜ å°„"""
    external_id: Optional[str] = None
    title_zh: Optional[str] = None
    resource_url: Optional[str] = None
    created_at: Optional[str] = None


class ImportRequest(BaseModel):
    """å¯¼å…¥è¯·æ±‚"""
    batch_name: Optional[str] = None
    column_mapping: Optional[Dict[str, str]] = None
    skip_duplicates: bool = True
    update_existing: bool = False


class ImportResponse(BaseModel):
    """å¯¼å…¥å“åº”"""
    batch_id: str
    total_records: int
    success_count: int
    failed_count: int
    skipped_count: int
    status: str
    errors: List[str] = []


@app.post("/import/data", response_model=ImportResponse)
async def import_data(
    file: UploadFile = File(...),
    skip_duplicates: bool = Form(True),
    update_existing: bool = Form(False),
    batch_name: Optional[str] = Form(None),
    column_mapping: Optional[str] = Form(None)
):
    """
    å¯¼å…¥Excel/CSVæ•°æ®åˆ°æ•°æ®åº“

    æ”¯æŒè‡ªåŠ¨æ£€æµ‹åˆ—åï¼Œä¹Ÿå¯æ‰‹åŠ¨æŒ‡å®šåˆ—æ˜ å°„ï¼š
    - external_id: å¤–éƒ¨IDï¼ˆç”¨äºå»é‡ï¼‰
    - title_zh: å•†å“åç§°
    - resource_url: èµ„æºé“¾æ¥
    - created_at: åˆ›å»ºæ—¶é—´

    è¿”å›å¯¼å…¥ç»“æœç»Ÿè®¡
    """
    import tempfile
    import os
    import json
    from services.import_service import DataImportService

    try:
        # æ£€æŸ¥æ–‡ä»¶ç±»å‹
        is_csv = file.filename.endswith('.csv')
        is_excel = file.filename.endswith('.xlsx') or file.filename.endswith('.xls')

        if not (is_csv or is_excel):
            raise HTTPException(status_code=400, detail="åªæ”¯æŒ Excel (.xlsx, .xls) æˆ– CSV (.csv) æ–‡ä»¶")

        # ä¿å­˜åˆ°ä¸´æ—¶æ–‡ä»¶
        suffix = '.csv' if is_csv else '.xlsx'
        with tempfile.NamedTemporaryFile(delete=False, suffix=suffix) as tmp:
            content = await file.read()
            tmp.write(content)
            tmp_path = tmp.name

        try:
            # è§£æåˆ—æ˜ å°„
            mapping = None
            if column_mapping:
                try:
                    mapping = json.loads(column_mapping)
                except:
                    pass

            # æ‰§è¡Œå¯¼å…¥
            service = DataImportService()
            if is_excel:
                result = service.import_from_excel(
                    file_path=tmp_path,
                    column_mapping=mapping,
                    batch_name=batch_name,
                    skip_duplicates=skip_duplicates,
                    update_existing=update_existing
                )
            else:
                result = service.import_from_csv(
                    file_path=tmp_path,
                    column_mapping=mapping,
                    batch_name=batch_name,
                    skip_duplicates=skip_duplicates,
                    update_existing=update_existing
                )

            return ImportResponse(**result)

        finally:
            # åˆ é™¤ä¸´æ—¶æ–‡ä»¶
            if os.path.exists(tmp_path):
                os.unlink(tmp_path)

    except Exception as e:
        raise HTTPException(status_code=500, detail=f"å¯¼å…¥å¤±è´¥: {str(e)}")


@app.get("/import/batches", response_model=List[Dict])
async def list_import_batches(limit: int = 50):
    """è·å–å¯¼å…¥æ‰¹æ¬¡åˆ—è¡¨"""
    from database.db_manager import get_db_context
    from database.crud import ImportBatchCRUD

    try:
        with get_db_context() as session:
            crud = ImportBatchCRUD(session)
            batches = crud.list_batches(limit=limit)
            return [batch.to_dict() for batch in batches]
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/import/batch/{batch_id}", response_model=Dict)
async def get_import_batch(batch_id: str):
    """è·å–å¯¼å…¥æ‰¹æ¬¡è¯¦æƒ…"""
    from database.db_manager import get_db_context
    from database.crud import ImportBatchCRUD

    try:
        with get_db_context() as session:
            crud = ImportBatchCRUD(session)
            batch = crud.get_batch(batch_id)
            if not batch:
                raise HTTPException(status_code=404, detail="æ‰¹æ¬¡ä¸å­˜åœ¨")
            return batch.to_dict()
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


# ==================== è¯¾ç¨‹/å•†å“æŸ¥è¯¢æ¥å£ ====================

class CourseSearchRequest(BaseModel):
    """è¯¾ç¨‹æœç´¢è¯·æ±‚"""
    keyword: Optional[str] = None
    resource_type: Optional[str] = None
    limit: int = 20
    offset: int = 0


class CourseItem(BaseModel):
    """è¯¾ç¨‹é¡¹"""
    product_id: str
    title_zh: Optional[str] = None
    resource_url: Optional[str] = None
    resource_type: Optional[str] = None
    external_id: Optional[str] = None
    created_at: Optional[str] = None


@app.post("/courses/search", response_model=List[CourseItem])
async def search_courses(req: CourseSearchRequest):
    """æœç´¢è¯¾ç¨‹"""
    from database.db_manager import get_db_context
    from database.models import ProductDB

    try:
        with get_db_context() as session:
            query = session.query(ProductDB).filter(
                ProductDB.external_id.isnot(None)
            )

            # å…³é”®è¯æœç´¢
            if req.keyword:
                query = query.filter(ProductDB.title_zh.contains(req.keyword))

            # èµ„æºç±»å‹ç­›é€‰
            if req.resource_type:
                query = query.filter(ProductDB.resource_type == req.resource_type)

            # åˆ†é¡µ
            courses = query.order_by(ProductDB.created_at.desc()).offset(req.offset).limit(req.limit).all()

            return [
                CourseItem(
                    product_id=c.product_id,
                    title_zh=c.title_zh,
                    resource_url=c.resource_url,
                    resource_type=c.resource_type,
                    external_id=c.external_id,
                    created_at=c.created_at.isoformat() if c.created_at else None
                )
                for c in courses
            ]
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/courses/stats")
async def get_courses_stats():
    """è·å–è¯¾ç¨‹ç»Ÿè®¡ä¿¡æ¯"""
    from database.db_manager import get_db_context
    from database.models import ProductDB

    try:
        with get_db_context() as session:
            total = session.query(ProductDB).filter(
                ProductDB.external_id.isnot(None)
            ).count()

            # æŒ‰ç±»å‹ç»Ÿè®¡
            from sqlalchemy import func
            type_stats = session.query(
                ProductDB.resource_type,
                func.count(ProductDB.product_id)
            ).filter(
                ProductDB.external_id.isnot(None)
            ).group_by(ProductDB.resource_type).all()

            return {
                "total": total,
                "by_type": {t or "unknown": c for t, c in type_stats}
            }
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/courses/{course_id}")
async def get_course(course_id: str):
    """è·å–å•ä¸ªè¯¾ç¨‹è¯¦æƒ…"""
    from database.db_manager import get_db_context
    from database.models import ProductDB, RawProductDataDB
    from database.crud import RawProductDataCRUD
    import json

    try:
        with get_db_context() as session:
            course = session.query(ProductDB).filter(
                ProductDB.product_id == course_id
            ).first()

            if not course:
                raise HTTPException(status_code=404, detail="è¯¾ç¨‹ä¸å­˜åœ¨")

            # è·å–åŸå§‹æ•°æ®
            raw_data = None
            if course.external_id:
                raw_data_crud = RawProductDataCRUD(session)
                raw_record = raw_data_crud.get_raw_data_by_external_id(course.external_id)
                if raw_record:
                    try:
                        raw_data = json.loads(raw_record.raw_data)
                    except:
                        raw_data = raw_record.raw_data

            return {
                "standard": {
                    "product_id": course.product_id,
                    "title_zh": course.title_zh,
                    "resource_url": course.resource_url,
                    "resource_type": course.resource_type,
                    "external_id": course.external_id,
                    "description": course.description,
                    "created_at": course.created_at.isoformat() if course.created_at else None,
                    "updated_at": course.updated_at.isoformat() if course.updated_at else None,
                },
                "raw_data": raw_data
            }
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

# ==================== äº§å“RAGç®¡ç†æ¥å£ ====================

class RAGRebuildRequest(BaseModel):
    """RAGé‡å»ºè¯·æ±‚"""
    source: Optional[str] = None  # æŒ‡å®šæ•°æ®æºï¼ŒNoneè¡¨ç¤ºå…¨éƒ¨é‡å»º


@app.get("/rag/product/status")
def get_product_rag_status():
    """è·å–äº§å“RAGç³»ç»ŸçŠ¶æ€"""
    from rag.product_rag import get_product_rag
    from rag.rag_config import DATA_SOURCE_CONFIGS

    try:
        rag = get_product_rag()

        status = {
            "enabled": True,
            "sources": []
        }

        for source_name, config in DATA_SOURCE_CONFIGS.items():
            collection = rag.vector_stores.get(source_name)
            status["sources"].append({
                "name": source_name,
                "collection_name": config.get("collection_name"),
                "indexed_count": collection.count() if collection else 0,
                "keywords": config.get("keywords", []),
            })

        return status

    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/rag/product/rebuild")
def rebuild_product_rag(req: RAGRebuildRequest):
    """
    é‡å»ºäº§å“RAGç´¢å¼•

    å½“æ•°æ®åº“æ•°æ®æ›´æ–°åï¼Œéœ€è¦è°ƒç”¨æ­¤æ¥å£é‡å»ºå‘é‡ç´¢å¼•
    """
    from rag.product_rag import get_product_rag

    try:
        rag = get_product_rag()

        if req.source:
            # é‡å»ºæŒ‡å®šæ•°æ®æº
            if req.source in rag.vector_stores:
                collection = rag.vector_stores[req.source]
                rag._chroma_client.delete_collection(
                    name=rag.rag_config.DATA_SOURCE_CONFIGS[req.source]["collection_name"]
                )
                # é‡æ–°åˆ›å»º
                collection_name = rag.rag_config.DATA_SOURCE_CONFIGS[req.source]["collection_name"]
                collection = rag._chroma_client.get_or_create_collection(name=collection_name)
                rag.vector_stores[req.source] = collection
                rag._build_index(req.source)
                return {"message": f"æ•°æ®æº {req.source} ç´¢å¼•é‡å»ºæˆåŠŸ"}
            else:
                raise HTTPException(status_code=404, detail=f"æ•°æ®æº {req.source} ä¸å­˜åœ¨")
        else:
            # é‡å»ºæ‰€æœ‰æ•°æ®æº
            rag.rebuild_all_indexes()
            return {"message": "æ‰€æœ‰æ•°æ®æºç´¢å¼•é‡å»ºæˆåŠŸ"}

    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/rag/product/search")
def product_rag_search(query: str, source: Optional[str] = None, top_k: int = 10):
    """
    ç›´æ¥æµ‹è¯•äº§å“RAGæ£€ç´¢

    ç”¨äºè°ƒè¯•å’Œæµ‹è¯•æ£€ç´¢æ•ˆæœ
    """
    from rag.product_rag import get_product_rag

    try:
        rag = get_product_rag()
        result = rag.search(query=query, source_name=source, top_k=top_k)
        return result

    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


if __name__ == "__main__":
    uvicorn.run(app, host="127.0.0.1", port=8000)

