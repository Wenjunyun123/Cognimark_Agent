import uvicorn
from fastapi import FastAPI, HTTPException, UploadFile, File
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from typing import List, Optional
import pandas as pd
import io
import json
import os
import uuid
from typing import List, Optional, Dict
from datetime import datetime

from llm_service import DeepSeekLLM
from data_model import default_store, Product
from agents import ProductSelectionAgent, MarketingCopyAgent

# åˆå§‹åŒ– FastAPI
app = FastAPI(title="AI Agent E-Commerce API", version="1.0")

# é…ç½® CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # å…è®¸æ‰€æœ‰æ¥æºè®¿é—®ï¼Œç”Ÿäº§ç¯å¢ƒè¯·æŒ‡å®šå…·ä½“åŸŸå
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# åˆå§‹åŒ–æœåŠ¡
llm = DeepSeekLLM()
selection_agent = ProductSelectionAgent(default_store, llm)
copy_agent = MarketingCopyAgent(llm)

# --- Pydantic Models ---

class ProductSimple(BaseModel):
    product_id: str
    title_en: str

class ProductDetail(BaseModel):
    product_id: str
    title_en: str
    category: str
    price_usd: float
    avg_rating: float
    monthly_sales: int
    main_market: str
    tags: str

class SelectionRequest(BaseModel):
    campaign_description: str
    target_market: Optional[str] = None
    top_k: int = 3

class SelectionResponse(BaseModel):
    products: List[ProductDetail]
    explanation: str

class CopyRequest(BaseModel):
    product_id: str
    target_language: str
    channel: str

class CopyResponse(BaseModel):
    copy_text: str

class ChatMessage(BaseModel):
    role: str  # 'user' or 'assistant'
    content: str

class ChatRequest(BaseModel):
    message: str
    context: Optional[str] = None
    history: Optional[List[ChatMessage]] = None
    session_id: Optional[str] = None

class ChatResponse(BaseModel):
    response: str
    message_id: str


class FileAnalysisResponse(BaseModel):
    summary: str
    data_preview: dict
    column_info: dict

# --- å­˜å‚¨ä¸Šä¼ çš„æ•°æ®ï¼ˆä¸´æ—¶ï¼Œå®é™…åº”ç”¨ä¸­åº”ä½¿ç”¨æ•°æ®åº“æˆ–ç¼“å­˜ï¼‰
uploaded_data_store = {}

# --- èŠå¤©å†å²æŒä¹…åŒ– ---
HISTORY_FILE = "chat_history.json"
# ç»“æ„: { session_id: [messages] }
CHAT_SESSIONS: Dict[str, List[Dict]] = {}

def load_history():
    """ä»æ–‡ä»¶åŠ è½½èŠå¤©å†å²"""
    global CHAT_SESSIONS
    if os.path.exists(HISTORY_FILE):
        try:
            with open(HISTORY_FILE, "r", encoding="utf-8") as f:
                CHAT_SESSIONS = json.load(f)
        except Exception as e:
            print(f"Error loading history: {e}")
            CHAT_SESSIONS = {}

def save_history():
    """ä¿å­˜èŠå¤©å†å²åˆ°æ–‡ä»¶"""
    try:
        with open(HISTORY_FILE, "w", encoding="utf-8") as f:
            json.dump(CHAT_SESSIONS, f, ensure_ascii=False, indent=2)
    except Exception as e:
        print(f"Error saving history: {e}")

# åˆå§‹åŒ–æ—¶åŠ è½½å†å²
load_history()

# --- Endpoints ---

@app.get("/products", response_model=List[ProductSimple])
def list_products():
    """è·å–æ‰€æœ‰å¯ç”¨äº§å“åˆ—è¡¨ (ID + Title)"""
    products = default_store.list_products()
    return [
        ProductSimple(product_id=p.product_id, title_en=p.title_en)
        for p in products
    ]

@app.post("/selection/recommend", response_model=SelectionResponse)
def recommend_products(req: SelectionRequest):
    """æ ¹æ® Campaign æè¿°æ¨èäº§å“"""
    try:
        top_products, explanation = selection_agent.recommend_products(
            campaign_description=req.campaign_description,
            target_market=req.target_market,
            top_k=req.top_k
        )
        
        # Convert data_model.Product objects to Pydantic models
        product_details = []
        for p in top_products:
            product_details.append(ProductDetail(
                product_id=p.product_id,
                title_en=p.title_en,
                category=p.category,
                price_usd=p.price_usd,
                avg_rating=p.avg_rating,
                monthly_sales=p.monthly_sales,
                main_market=p.main_market,
                tags=p.tags
            ))
            
        return SelectionResponse(products=product_details, explanation=explanation)
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/marketing/generate", response_model=CopyResponse)
def generate_copy(req: CopyRequest):
    """ç”Ÿæˆè¥é”€æ–‡æ¡ˆ"""
    product = default_store.get_product(req.product_id)
    if not product:
        raise HTTPException(status_code=404, detail="Product not found")
    
    try:
        result = copy_agent.generate_copy(
            product=product,
            target_language=req.target_language,
            channel=req.channel
        )
        return CopyResponse(copy_text=result)
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/agent/history", response_model=List[ChatMessage])
def get_chat_history(session_id: Optional[str] = None):
    """è·å–å†å²å¯¹è¯è®°å½•"""
    if session_id and session_id in CHAT_SESSIONS:
        return [
            ChatMessage(role=msg["role"], content=msg["content"])
            for msg in CHAT_SESSIONS[session_id]
        ]
    return []

@app.post("/agent/chat", response_model=ChatResponse)
def chat_with_agent(req: ChatRequest):
    """é€šç”¨æ™ºèƒ½ä½“å¯¹è¯æ¥å£ï¼ˆæ”¯æŒå¤šè½®å¯¹è¯ï¼‰"""
    try:
        # 1. ç¡®å®šä¼šè¯ä¸Šä¸‹æ–‡
        session_id = req.session_id
        current_history = []
        
        if session_id:
            # åªæœ‰éä¸´æ—¶ä¼šè¯ï¼ˆä¸ä»¥ 'temp_' å¼€å¤´ï¼‰æ‰ä¿å­˜åˆ°æ–‡ä»¶
            is_temp_session = session_id.startswith('temp_')
            
            if not is_temp_session and session_id not in CHAT_SESSIONS:
                CHAT_SESSIONS[session_id] = []
                current_history = CHAT_SESSIONS[session_id]
            elif not is_temp_session:
                current_history = CHAT_SESSIONS[session_id]
            else:
                # ä¸´æ—¶ä¼šè¯ä½¿ç”¨å†…å­˜ä¸­çš„ä¸´æ—¶å­˜å‚¨ï¼Œä¸æŒä¹…åŒ–
                # è¿™é‡Œæˆ‘ä»¬ç®€å•å¤„ç†ï¼šä¸´æ—¶ä¼šè¯ä¹Ÿç”¨ current_history æš‚å­˜ï¼Œä½†ä¸å†™å…¥æ–‡ä»¶
                # æˆ–è€…ï¼Œå¦‚æœå‰ç«¯æ¯æ¬¡éƒ½å‘å®Œæ•´ historyï¼Œè¿™é‡Œç”šè‡³å¯ä»¥ä¸éœ€è¦ current_history
                pass
        
        # 2. å¦‚æœæœ‰ session_id ä¸”éä¸´æ—¶ï¼Œä¿å­˜ç”¨æˆ·æ¶ˆæ¯åˆ°åç«¯å†å²
        if session_id and not session_id.startswith('temp_'):
            user_msg_entry = {
                "role": "user", 
                "content": req.message,
                "timestamp": datetime.now().isoformat()
            }
            if current_history is not None:
                current_history.append(user_msg_entry)
                save_history()

        # æ£€æµ‹åˆ†ææ¨¡å¼
        mode_prompts = {
            '[å¸‚åœºè¶‹åŠ¿åˆ†ææ¨¡å¼]': "You are a market analysis expert. Focus on market trends, opportunities, competitive landscape, and data-driven insights. Provide actionable recommendations based on data.",
            '[é€‰å“ç­–ç•¥å»ºè®®æ¨¡å¼]': "You are a product selection strategist. Focus on product recommendations, category analysis, profit potential, and market fit. Use data to support your suggestions.",
            '[å¹¿å‘Šä¼˜åŒ–å»ºè®®æ¨¡å¼]': "You are an advertising optimization expert. Focus on ad performance, ROI improvement, targeting strategies, and campaign optimization. Provide specific, measurable advice.",
            '[è½¬åŒ–ç‡ä¼˜åŒ–æ¨¡å¼]': "You are a conversion rate optimization specialist. Focus on user experience, funnel optimization, A/B testing, and conversion tactics. Give practical improvement steps."
        }
        
        # æ£€æŸ¥æ˜¯å¦ä½¿ç”¨ç‰¹å®šæ¨¡å¼
        system_prompt = "You are CogniMark, a helpful AI assistant specialized in cross-border e-commerce, product selection, and marketing. You provide professional, actionable advice. Maintain conversation context and refer to previous messages when relevant."
        user_message = req.message
        
        for mode_key, mode_system in mode_prompts.items():
            if user_message.startswith(mode_key):
                system_prompt = mode_system + " Maintain conversation context and refer to previous messages when relevant."
                user_message = user_message.replace(mode_key, '').strip()
                break
        
        # æ£€æŸ¥æ˜¯å¦æœ‰ä¸Šä¼ çš„æ•°æ®
        uploaded_data_context = ""
        if uploaded_data_store:
            uploaded_data_context = "\n\nå·²ä¸Šä¼ çš„å¤–éƒ¨æ•°æ®æ‘˜è¦:\n"
            for filename, data_info in uploaded_data_store.items():
                uploaded_data_context += f"- {filename}: {data_info['rows']} è¡Œ, {data_info['columns']} åˆ—\n"
                uploaded_data_context += f"  åˆ—å: {', '.join(data_info['column_names'])}\n"
                
                # å¦‚æœæœ‰æ•°æ®ï¼Œæä¾›æ›´è¯¦ç»†çš„ä¸Šä¸‹æ–‡
                df = data_info.get('dataframe')
                if df is not None:
                    uploaded_data_context += f"  æ•°æ®é¢„è§ˆï¼ˆå‰3è¡Œï¼‰:\n{df.head(3).to_string()}\n"
        
        # æ„å»ºæœ€ç»ˆçš„ç”¨æˆ·æç¤º
        final_prompt = ""
        if req.context:
            final_prompt += f"Context: {req.context}\n"
        if uploaded_data_context:
            final_prompt += uploaded_data_context
        final_prompt += f"\nUser question: {user_message}"
        
        # 3. å‡†å¤‡ LLM å†å²ä¸Šä¸‹æ–‡
        llm_history = []
        
        if session_id and not session_id.startswith('temp_'):
            # ä½¿ç”¨åç«¯å­˜å‚¨çš„å†å²ï¼ˆæ’é™¤åˆšåˆšåŠ å…¥çš„å½“å‰æ¶ˆæ¯ï¼‰
            # æ³¨æ„ï¼šcurrent_history å¯èƒ½æ˜¯å¼•ç”¨ï¼Œä¿®æ”¹å®ƒä¼šå½±å“å…¨å±€
            if current_history:
                for msg in current_history[:-1]:
                    llm_history.append({
                        "role": msg["role"],
                        "content": msg["content"]
                    })
        elif req.history:
            # å¦‚æœæ²¡æœ‰ session_id æˆ–ä¸ºä¸´æ—¶ä¼šè¯ï¼Œä½¿ç”¨å‰ç«¯ä¼ æ¥çš„ history
            for msg in req.history:
                llm_history.append({
                    "role": msg.role,
                    "content": msg.content
                })
        
        response_text = llm.chat(system_prompt, final_prompt, history=llm_history)
        
        # 4. å¦‚æœæœ‰ session_id ä¸”éä¸´æ—¶ï¼Œä¿å­˜åŠ©æ‰‹å›å¤åˆ°åç«¯å†å²
        if session_id and not session_id.startswith('temp_'):
            assistant_msg_entry = {
                "role": "assistant",
                "content": response_text,
                "timestamp": datetime.now().isoformat()
            }
            if current_history is not None:
                current_history.append(assistant_msg_entry)
                save_history()
        
        return ChatResponse(response=response_text, message_id=str(uuid.uuid4()))
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/upload/excel", response_model=FileAnalysisResponse)
async def upload_excel(file: UploadFile = File(...)):
    """ä¸Šä¼  Excel/CSV æ–‡ä»¶ï¼ˆä»…åŠ è½½ï¼Œä¸åˆ†æï¼‰"""
    try:
        # æ£€æŸ¥æ–‡ä»¶ç±»å‹
        is_csv = file.filename.endswith('.csv')
        is_excel = file.filename.endswith('.xlsx') or file.filename.endswith('.xls')
        
        if not (is_csv or is_excel):
            raise HTTPException(status_code=400, detail="åªæ”¯æŒ Excel (.xlsx, .xls) æˆ– CSV (.csv) æ–‡ä»¶")
        
        # è¯»å–æ–‡ä»¶
        contents = await file.read()
        
        if is_csv:
            # å°è¯•ä¸åŒçš„ç¼–ç 
            try:
                df = pd.read_csv(io.BytesIO(contents), encoding='utf-8')
            except UnicodeDecodeError:
                try:
                    df = pd.read_csv(io.BytesIO(contents), encoding='gbk')
                except UnicodeDecodeError:
                    df = pd.read_csv(io.BytesIO(contents), encoding='latin1')
        else:
            df = pd.read_excel(io.BytesIO(contents))
        
        # åŸºæœ¬ä¿¡æ¯
        rows, cols = df.shape
        column_names = df.columns.tolist()
        
        # æ•°æ®é¢„è§ˆï¼ˆå‰5è¡Œï¼‰
        preview = df.head(5).to_dict(orient='records')
        
        # åˆ—ä¿¡æ¯ï¼ˆæ•°æ®ç±»å‹ã€éç©ºæ•°é‡ç­‰ï¼‰
        column_info = {}
        for col in df.columns:
            column_info[col] = {
                'dtype': str(df[col].dtype),
                'non_null_count': int(df[col].count()),
                'null_count': int(df[col].isnull().sum()),
                'unique_count': int(df[col].nunique())
            }
            
            # å¦‚æœæ˜¯æ•°å€¼å‹ï¼Œæ·»åŠ ç»Ÿè®¡ä¿¡æ¯
            if pd.api.types.is_numeric_dtype(df[col]):
                column_info[col]['mean'] = float(df[col].mean()) if not df[col].isnull().all() else None
                column_info[col]['min'] = float(df[col].min()) if not df[col].isnull().all() else None
                column_info[col]['max'] = float(df[col].max()) if not df[col].isnull().all() else None
        
        # å­˜å‚¨æ•°æ®ä¿¡æ¯ï¼ˆç”¨äºåç»­åˆ†æï¼‰
        uploaded_data_store[file.filename] = {
            'dataframe': df,
            'rows': rows,
            'columns': cols,
            'column_names': column_names
        }
        
        # åªè¿”å›åŸºæœ¬ä¿¡æ¯ï¼Œä¸è¿›è¡Œ AI åˆ†æ
        summary = f"æ–‡ä»¶å·²æˆåŠŸåŠ è½½ï¼\n\nğŸ“Š æ•°æ®è§„æ¨¡: {rows} è¡Œ Ã— {cols} åˆ—\nğŸ“‹ åˆ—å: {', '.join(column_names[:5])}{'...' if len(column_names) > 5 else ''}"
        
        return FileAnalysisResponse(
            summary=summary,
            data_preview={'rows': preview[:5]},
            column_info=column_info
        )
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"æ–‡ä»¶å¤„ç†å¤±è´¥: {str(e)}")

@app.get("/upload/files")
def list_uploaded_files():
    """è·å–å·²ä¸Šä¼ æ–‡ä»¶åˆ—è¡¨"""
    return {
        "files": [
            {
                "filename": filename,
                "rows": info['rows'],
                "columns": info['columns'],
                "column_names": info['column_names']
            }
            for filename, info in uploaded_data_store.items()
        ]
    }

@app.delete("/upload/file/{filename}")
def delete_uploaded_file(filename: str):
    """åˆ é™¤å·²ä¸Šä¼ çš„æ–‡ä»¶"""
    if filename in uploaded_data_store:
        del uploaded_data_store[filename]
        return {"message": f"æ–‡ä»¶ {filename} å·²åˆ é™¤"}
    else:
        raise HTTPException(status_code=404, detail="æ–‡ä»¶ä¸å­˜åœ¨")

if __name__ == "__main__":
    uvicorn.run(app, host="127.0.0.1", port=8000)

